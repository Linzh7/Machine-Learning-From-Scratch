{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596506264389",
   "display_name": "Python 3.8.3 64-bit ('anaconda3': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrebuiltData:\n",
    "    def Fx(x, a=0, b=3, c=3):\n",
    "        return a * x**2 + b * x + c\n",
    "\n",
    "    def MyData(rangeStart=0, rangeEnd=100, rangeNum=100, randomFloat=1):\n",
    "        data_x = np.linspace(rangeStart, rangeEnd, rangeNum)\n",
    "        random = np.random.randn(len(data_x))\n",
    "        data_y = PrebuiltData.Fx(data_x) + randomFloat * random\n",
    "        return data_x, data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cost:\n",
    "    def LinerRegressionCost(data, predict):\n",
    "        if len(data) != len(predict):\n",
    "            print(\"Lengths of two data list are not equal.\")\n",
    "            return 0x7fffffff\n",
    "        bias = 0\n",
    "        for index in range(0, len(data)):\n",
    "            bias += ((data[index] - predict[index])**2) / 2\n",
    "        bias /= 2\n",
    "        return bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Enumerate:\n",
    "    def LinerRegressionEnumerate(data_x, data_y, maxRange=100, stepSize=1):\n",
    "        cost = 0x7fffffff\n",
    "        costSave = 0x7fffffff\n",
    "        kSave = 0\n",
    "        bSave = 0\n",
    "        for k in range(0, maxRange, stepSize):\n",
    "            for b in range(0, maxRange, stepSize):\n",
    "                predict_y = list(map(lambda x: x * k + b, data_x))\n",
    "                cost = Cost.LinerRegressionCost(data_y, predict_y, k, b)\n",
    "                if cost < costSave:\n",
    "                    kSave = k\n",
    "                    bSave = b\n",
    "                    costSave = cost\n",
    "                    # print(k, b, cost)\n",
    "        return kSave, bSave, costSave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x, data_y=PrebuiltData.MyData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0 0 775806.4415258527\n0 1 768185.0704060035\n0 2 760613.6992861541\n0 3 753092.3281663049\n0 4 745620.9570464555\n0 5 738199.5859266063\n0 6 730828.2148067575\n0 7 723506.843686908\n0 8 716235.4725670586\n0 9 709014.1014472094\n0 10 701842.7303273602\n0 11 694721.359207511\n0 12 687649.9880876617\n0 13 680628.6169678124\n0 14 673657.2458479634\n0 15 666735.8747281141\n0 16 659864.5036082647\n0 17 653043.1324884152\n0 18 646271.7613685661\n0 19 639550.3902487169\n0 20 632879.0191288678\n0 21 626257.6480090184\n0 22 619686.2768891691\n0 23 613164.9057693199\n0 24 606693.5346494706\n0 25 600272.1635296214\n0 26 593900.792409772\n0 27 587579.4212899228\n0 28 581308.0501700736\n0 29 575086.6790502245\n0 30 568915.3079303751\n0 31 562793.9368105258\n0 32 556722.5656906767\n0 33 550701.1945708273\n0 34 544729.8234509781\n0 35 538808.4523311289\n0 36 532937.0812112797\n0 37 527115.7100914302\n0 38 521344.338971581\n0 39 515622.96785173187\n0 40 509951.5967318826\n0 41 504330.2256120334\n0 42 498758.85449218407\n0 43 493237.48337233474\n0 44 487766.11225248536\n0 45 482344.7411326363\n0 46 476973.37001278705\n0 47 471651.99889293785\n0 48 466380.62777308864\n0 49 461159.25665323937\n0 50 455987.88553339004\n0 51 450866.51441354066\n0 52 445795.14329369145\n0 53 440773.77217384253\n0 54 435802.40105399303\n0 55 430881.0299341439\n0 56 426009.65881429455\n0 57 421188.2876944453\n0 58 416416.91657459585\n0 59 411695.5454547468\n0 60 407024.17433489754\n0 61 402402.8032150482\n0 62 397831.432095199\n0 63 393310.0609753496\n0 64 388838.6898555004\n0 65 384417.3187356512\n0 66 380045.94761580194\n0 67 375724.57649595273\n0 68 371453.20537610346\n0 69 367231.83425625425\n0 70 363060.463136405\n0 71 358939.09201655566\n0 72 354867.72089670645\n0 73 350846.3497768573\n0 74 346874.97865700803\n0 75 342953.6075371586\n0 76 339082.2364173094\n0 77 335260.8652974602\n0 78 331489.49417761085\n0 79 327768.12305776164\n0 80 324096.7519379123\n0 81 320475.38081806316\n0 82 316904.00969821395\n0 83 313382.63857836474\n0 84 309911.2674585154\n0 85 306489.8963386662\n0 86 303118.5252188168\n0 87 299797.1540989677\n0 88 296525.7829791184\n0 89 293304.41185926914\n0 90 290133.0407394199\n0 91 287011.6696195706\n0 92 283940.29849972134\n0 93 280918.9273798721\n0 94 277947.5562600228\n0 95 275026.1851401736\n0 96 272154.8140203244\n0 97 269333.4429004751\n0 98 266562.0717806259\n0 99 263840.7006607766\n1 19 261022.15769355453\n1 20 256850.7865737053\n1 21 252729.41545385608\n1 22 248658.0443340068\n1 23 244636.67321415752\n1 24 240665.3020943083\n1 25 236743.93097445907\n1 26 232872.55985460975\n1 27 229051.18873476048\n1 28 225279.81761491133\n1 29 221558.44649506203\n1 30 217887.07537521273\n1 31 214265.7042553635\n1 32 210694.33313551426\n1 33 207172.96201566496\n1 34 203701.5908958158\n1 35 200280.2197759665\n1 36 196908.8486561172\n1 37 193587.477536268\n1 38 190316.10641641874\n1 39 187094.73529656942\n1 40 183923.36417672024\n1 41 180801.99305687097\n1 42 177730.6219370217\n1 43 174709.25081717243\n1 44 171737.87969732328\n1 45 168816.50857747396\n1 46 165945.13745762472\n1 47 163123.76633777545\n1 48 160352.39521792615\n1 49 157631.02409807694\n1 50 154959.65297822768\n1 51 152338.28185837847\n1 52 149766.9107385292\n1 53 147245.53961867993\n1 54 144774.1684988307\n1 55 142352.7973789814\n1 56 139981.42625913216\n1 57 137660.05513928292\n1 58 135388.68401943363\n1 59 133167.3128995844\n1 60 130995.94177973516\n1 61 128874.57065988588\n1 62 126803.19954003667\n1 63 124781.82842018736\n1 64 122810.45730033812\n1 65 120889.08618048891\n1 66 119017.7150606396\n1 67 117196.34394079034\n1 68 115424.97282094111\n1 69 113703.60170109186\n1 70 112032.2305812426\n1 71 110410.85946139337\n1 72 108839.48834154411\n1 73 107318.11722169488\n1 74 105846.74610184561\n1 75 104425.37498199634\n1 76 103054.0038621471\n1 77 101732.63274229785\n1 78 100461.26162244858\n1 79 99239.89050259932\n1 80 98068.51938275005\n1 81 96947.14826290082\n1 82 95875.77714305154\n1 83 94854.40602320233\n1 84 93883.03490335302\n1 85 92961.66378350377\n1 86 92090.29266365457\n1 87 91268.92154380529\n1 88 90497.55042395604\n1 89 89776.17930410679\n1 90 89104.80818425753\n1 91 88483.4370644083\n1 92 87912.06594455903\n1 93 87390.69482470976\n1 94 86919.32370486054\n1 95 86497.95258501127\n1 96 86126.58146516197\n1 97 85805.21034531281\n1 98 85533.83922546348\n1 99 85312.46810561424\n2 3 83544.2805643978\n2 4 81072.90944454857\n2 5 78651.53832469933\n2 6 76280.16720485003\n2 7 73958.79608500078\n2 8 71687.42496515153\n2 9 69466.05384530229\n2 10 67294.682725453\n2 11 65173.31160560377\n2 12 63101.94048575453\n2 13 61080.56936590528\n2 14 59109.198246056\n2 15 57187.82712620674\n2 16 55316.45600635749\n2 17 53495.084886508244\n2 18 51723.713766659006\n2 19 50002.34264680974\n2 20 48330.97152696049\n2 21 46709.60040711123\n2 22 45138.22928726197\n2 23 43616.85816741272\n2 24 42145.487047563474\n2 25 40724.11592771422\n2 26 39352.744807864954\n2 27 38031.37368801571\n2 28 36760.002568166456\n2 29 35538.6314483172\n2 30 34367.26032846796\n2 31 33245.8892086187\n2 32 32174.518088769437\n2 33 31153.14696892019\n2 34 30181.775849070935\n2 35 29260.40472922168\n2 36 28389.033609372433\n2 37 27567.662489523173\n2 38 26796.291369673927\n2 39 26074.920249824667\n2 40 25403.54912997541\n2 41 24782.178010126154\n2 42 24210.806890276905\n2 43 23689.435770427648\n2 44 23218.0646505784\n2 45 22796.693530729142\n2 46 22425.322410879882\n2 47 22103.951291030626\n2 48 21832.58017118138\n2 49 21611.209051332124\n2 50 21439.83793148289\n2 51 21318.466811633625\n2 52 21247.09569178437\n2 53 21225.72457193512\n3 0 246.99638561827226\n3 1 125.62526576901863\n3 2 54.25414591976496\n3 3 32.88302607051127\n3 3 32.88302607051127\n"
    }
   ],
   "source": [
    "k,b,cost=Enumerate.LinerRegressionEnumerate(data_x,data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "3 3 32.88302607051127\n"
    }
   ],
   "source": [
    "print(k,b,cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}